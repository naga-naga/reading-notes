# 第1章 ジェイウォーク（信号無視）
- 多対多を表現する際に、カンマ区切りの文字列などでデータを保持してしまうアンチパターン
- 問題
  - 正規表現で値を取り出すなどの操作が必要になり、クエリを作るのが面倒になる
  - インデックスを使えずパフォーマンスが落ちる
  - 集約クエリが上手く使えない
  - 値の更新時にソート順を維持できない
  - 値の妥当性の検証ができない
    - 全部文字列で入れることになるため
  - 区切り文字をどうするのか
  - リストの長さの制限をどう決めるのか
- 解決策
  - 多対多のテーブルを繋ぐ中間テーブルを作成する
  - 上記問題が解決するほか、各エントリに属性を追加できる

# 第2章 ナイーブツリー
- ツリー構造をデータベース上で扱う場合の話
- アンチパターン
  - `parent_id` のようなカラムを持ち、親のみに依存する方法
  - 隣接リストというらしい
- 問題点
  - 単純なクエリでは2つの階層しか見ることができない
    - 「あるノードの全ての子孫を取得する」といったクエリが書けない
      - 階層の分だけ `JOIN` が必要になる
    - かといって階層の数を制限するのも苦しい
      - ツリーにするということは、大抵の場合において深さに制限はないはず
  - ノードの削除が大変
    - リーフノード以外を削除した場合に、 `parent_id` の更新が必要になる
- アンチパターンを使ってもよい場合
  - 直近の親子のみを参照し、削除も行わないような場合
  - 再帰クエリ構文がサポートされている場合
- 解決策
  - 経路列挙(Path Enumeration, Materialized Path)
    - `'1/2/3/4/` のような形で、親子関係をパスの形にする
    - 先祖や子孫の参照が容易
    - パスの文字列の上限の問題がある
      - 第1章のジェイウォークと同じ問題
  - 入れ子集合(Nested Set)
    - ツリーを深さ優先探索して、ノードの左と右にそれぞれ番号を振っていく
    - 削除が容易
    - 直近の親の取得が大変
    - ノードの挿入や移動などの操作も面倒
      - ノードの左右の数値を毎回計算する必要がある
  - 閉包テーブル(Closure Table)
    - ツリー全体の先祖・子孫の関係を保持するテーブルを作る
    - 先祖や子孫の取得が容易
    - 削除も容易
      - ただし、閉包テーブルから消しても、本体は消されないことに注意
      - 関係性を柔軟に変更できる
    - 行数が多く、スペースを消費するというトレードオフ

# 第3章 ID Required
- 主キーとしてどのテーブルにも `AUTO INCREMENT` な `INTEGER` の `id` 列を作るアンチパターン
- 問題
  - 冗長なキーが作成されてしまう
    - 自然キー（ナチュラルキー）として使える列があるのに、わざわざ `id` 列を作るのは無駄
  - 重複行を許可してしまう
    - 交差テーブルにおいて `id` 列を主キーとすると、交差テーブルで繋ぐ二つのテーブルのそれぞれの主キー列のペアの重複を許してしまう
    - 主キー列のペアに `UNIQUE` 制約を付ける必要があるが、そうすると `id` 列は不要では？ という話
  - キーの意味が分かりづらくなる
    - `bug_id` や `account_id` などのような名前の方が分かりやすい
  - SQL の `USING` が使えない
    - `JOIN` で結合する際のカラム名が同じ場合、`USING` が使える
    - `id` 列を使うと `USING` で `JOIN` できない
- アンチパターンを使ってもよい場合
  - フレームワークで規定されている場合
    - Rails などまさにそう
  - 自然キーが長すぎる場合
- 解決策
  - 分かりやすい名前を付ける
    - 例えば `Bugs` テーブルの主キーは `bug_id`
  - 規約に縛られない
    - 必ずしもフレームワークに従う必要はない
      - 従った方が楽な気もしている
    - 新規のプロジェクトでこそ列名の明示的な指定が重要らしい
  - 自然キーや複合キーの活用
    - `NOT NULL` かつ `UNIQUE` な列があるのなら、疑似キーは不要
      - 自然キーとして使えそうな列が重複を許すようになってしまった場合は、疑似キーを作成するしかない
      - そういうことも織り込んで、初めから疑似キーを使うのが楽なのでは？ と思う
    - 交差テーブルでは複合キーを使った方が良さそう

# 第4章 キーレスエントリ（外部キー嫌い）
- 外部キーを使わないというアンチパターン
- 問題
  - アプリケーション側がミスなく参照整合性を保たなければならなくなる
    - 無理
  - 壊れた参照がないか、頻繁にチェックしなければならない
    - 壊れた参照を検出したときにどう対応するのか、という問題もある
  - `UPDATE` のジレンマ
    - 親子を同時に更新する必要があるが、それはできない
- アンチパターンを使ってもよい場合
  - 外部キー制約をサポートしていないデータベース製品を使う場合
    - 何かしらの代替手法で参照整合性を保証する必要がある
  - 現代においてそんなデータベース製品はあるのか……？
- 解決策
  - 外部キーを使う
    - どのようなクエリであれ、参照整合性を強制できる
    - `ON UPDATE` や `ON DELETE` で、カスケード処理をデータベースに任せられる
    - オーバーヘッドにもならない
      - 外部キーを使わない方がかえって遅い

# 第5章 EAV
- 可変属性を扱うために `(id, attribute_name, value)` といったように、行に属性を格納しようとするアンチパターン
  - オブジェクト指向における継承関係をデータベースで表そうとすると起こりやすい？
- 問題
  - クエリが複雑になる
    - 普通のテーブル設計なら `SELECT` するだけで良いところが、属性名を `WHERE` で比較して値を取り出す必要がある
  - データの整合性が保てない
    - `NOT NULL` 属性が使えない
    - `date` や `integer` といったデータ型が使えないので、無効なデータを拒否できない
    - 参照整合性を強制できない
    - 属性名がブレる可能性がある
  - 行の再構築が必要
    - 普通のテーブル設計の場合、1行に全ての属性が入っている
    - EAV の場合は1行に1属性なので、全ての属性を1行で取りたい場合は再構築が必要
- アンチパターンを使ってもよい場合
  - リレーショナルデータベースの長所を潰すので、そうそう使えるものではない
  - そもそもリレーショナルデータベースでやろうとしているのが間違いかもしれないので、KVS などの使用を検討したほうがいいかもしれない
- 解決策
  - シングルテーブル継承(Single Table Inheritance)
    - STI とも言うらしい
    - 1つのテーブルに、全てのサブタイプを格納する
    - サブタイプを区別するための列を追加する
    - 欠点
      - どの属性がどのサブタイプに属するものかを定義するメタデータが無いため、開発者自身が管理する必要がある
    - 使いどころ
      - サブタイプの数とサブタイプ固有の属性が少ない
      - Active Record パターンのような場合
  - 具象テーブル継承(Concrete Table Inheritance)
    - サブタイプごとにテーブルを作る
    - 利点
      - 存在しない属性は設定できない
      - サブタイプを表す列が不要
    - 欠点
      - 共通の属性と固有の属性の区別が難しい
      - サブタイプの種類を問わず全てのオブジェクトを取得したい場合が面倒
    - 使いどころ
      - 全てのサブタイプを跨いだ検索の頻度が少ない場合
  - クラステーブル継承(Class Table Inheritance)
    - オブジェクト指向のクラスのようにテーブルを作る
    - 共通属性で一つのテーブル、サブタイプごとに固有の属性でそれぞれのテーブル
    - 利点
      - 1対1の関連が強制できる
      - 共通の属性を参照する場合に限り、全てのサブタイプにまたがる検索を効率よく行える
    - 使いどころ
      - 全てのサブタイプに共通する列を参照するクエリの実行頻度が高い場合
  - 半構造化データ
    - `BLOB` や `TEXT` などの Large Object 列を追加し、XML や JSON などの形で属性名と値を保存
    - 利点
      - 拡張性が極めて高い
    - 欠点
      - SQL で特定の属性にアクセスできないため、アプリケーションコード側でフィルタ・集約・ソートなどの処理を書く必要がある
    - 使いどころ
      - サブタイプの数が多い場合
      - 頻繁に新しい属性を追加する必要がある場合
  - どうしても EAV を使わざるを得ない場合
    - 行の集合として属性を取得するクエリを書くように気を付ける

# 第6章 ポリモーフィック関連
- あるテーブルを複数の親テーブルに関連付けようとするアンチパターン
- 問題
  - どの親テーブルに紐づくかを区別するための文字列型の列が必要になり、参照整合性制約を定義できない
    - EAV でも似たような問題があったな
    - データへのメタデータの混入が見られたら、それは良くない設計のにおいかもしれない
  - 全てのレコードを取得しようとすると、複数の親レコード全てを `OUTER JOIN` する必要がある
    - SQL では動的に結合するテーブルを変えられないため
    - `OUTER_JOIN` なので結合しない列が `NULL` になる
  - 親テーブル同士が全く関係ない場合にも使われうる
    - すぐに複雑化していく
- アンチパターンを使ってもよい場合
  - なるべく使わないほうが良い
  - ORM フレームワークによってはポリモーフィック関連を使わざるを得ない場合がある
- 解決策
  - 中間テーブルを作成する
    - 親と子を多対多でつなぐテーブルを作成する
    - 親テーブルを区別するための文字列の列が不要になる
    - `UNIQUE` 制約を宣言することで、1つの親に1つの子、という制約を作れる
      - 複数の親に紐づくことは避けられないため、そこはアプリケーション側でやる必要がある
  - 共通の親テーブルを作成する
    - EAV の章のクラステーブル継承
    - 共通の親テーブルに対して関連付ければよい

# 第7章 マルチカラムアトリビュート
- 複数の値を持つ属性を格納する際に、複数の列を定義するアンチパターン
- 問題
  - 第1章の「ジェイウォーク」アンチパターンと同じような問題が起こる
  - 値の検索が面倒
    - 例えばある属性を格納する列を3列用意した場合、検索する際に毎回3列すべてを見る必要がある
  - 値の追加と削除も面倒
    - 追加や削除の前にどの列が空いているかを確認して `UPDATE` する必要がある
  - 一意性が保証できない
    - 列が分かれているため `UNIQUE` 制約は使えない
  - 値が増えたときどうするか
    - 3列では足りないかもしれない
    - 足りなくなったらその度に列を増やすのか？
    - 列を増やすと既存クエリも修正する必要がある
- アンチパターンを使ってもよい場合
  - それぞれの値が別の意味合いで使われる場合
  - 同じ `Account` であっても、「バグの報告者」「バグ修正を行うプログラマ」「修正を確認する品質管理者」などでは意味が異なる
- 解決策
  - 従属テーブルを作成する
    - 列方向ではなく行方向にデータを増やしていく
    - 単純にテーブルを分けて関連付けるだけ

# 第8章 メタデータトリブル
- スケーラビリティを高めたい時に、テーブルや列をコピーするアンチパターン
  - 「トリブル」はスタートレックに出てくる生き物らしい
- 問題
  - テーブルの増殖
    - 年毎にテーブルを分けるとすると、年が明ける度にテーブルを追加する必要がある
    - 追加し忘れるとエラーが発生するようになってしまう
  - データの整合性
    - `CHECK` 制約を付けることはできる
    - テーブルを増やす際に `CHECK` 制約の値を変更する必要がある
  - データの同期
    - データの修正により、別のテーブルにデータを移さなければならない場合が生じる
  - 一意性の保証
    - 分かたれたテーブル全体で主キーが一意でなければならない
    - 場合によっては主キーを生成するためだけに新たにテーブルを作成する必要がある
  - テーブルをまたいだクエリ実行
    - `UNION` で全てのテーブルをつなげる必要がある
    - テーブルが増える度にクエリの修正が必要になる
  - メタデータの同期
    - 列が増える場合、全てのテーブルに列を追加する必要がある
  - 参照整合性の管理
    - テーブルが複数に分かれると、外部キーを定義できない
- アンチパターンを使ってもよい場合
  - 過去のデータをアーカイブしたい場合
  - もうほとんど参照しないのであれば、テーブルを分けてしまってもよいかもしれない
- 解決策
  - 水平パーティショニング
    - 行ごとに別々の論理テーブルに分割する
    - データベースがサポートしている
  - 垂直パーティショニング
    - 列の一部だけサイズが大きい場合などに有効
    - 大きなバイナリファイルだけを別のテーブルに分けるなど
  - 従属テーブル
    - 強引に1行にまとめようとせず、年との組み合わせで1行作るようにする

# 第9章 ラウンディングエラー（丸め誤差）
- `FLOAT` 型を使うアンチパターン
- 問題
  - 丸め誤差の発生
  - 等価比較ができない
  - 集約関数で誤差が広がる
- アンチパターンを使ってもよい場合
  - 科学技術計算を行うような場合
- 解決策
  - `NUMERIC` 型や `DECIMAL` 型を使う

# 第10章 サーティワンフレーバー
- 列定義で値を限定するアンチパターン
  - `ENUM` など
- 問題
  - 許可された値の一覧を取得するのが大変
    - テーブルのメタデータを読み、文字列で返ってくる情報をパースし、必要な情報を取りだす必要がある
  - 新たな値を追加するのが大変
    - 列定義を変更する必要がある
    - 現在許可されている値のリストを知っておく必要がある
    - データベースによっては列が空である必要があり、そのような場合には ETL(Extract, Transform, Load) 処理が必要
  - 値を廃止したいときが苦しい
    - 廃止予定の既存の値をどうするか
    - 廃止予定の値も残しておきたいが使いたくはない、という場合にどうするのか
  - 移植が困難
    - 例えば `ENUM` は MySQL のみらしい
    - 列定義の仕様はデータベース製品により異なるため、移植が大変
- アンチパターンを使ってもよい場合
  - 値の変更が不要であると断言できる場合
    - 右と左、有効と無効、オンとオフなど、相互排他的な2つの値を格納したい場合
- 解決策
  - 限定する値の一覧を保持するテーブルを作成し、外部キー制約で参照する
    - 値の追加や更新が容易
    - 廃止された値も、 `active` のような列を追加することで対応可能

# 第11章 ファントムファイル
- 画像ファイルをデータベースの外に格納するアンチパターン
  - データベースにはファイルパスのみを保存しておき、画像ファイル自体は外のファイルシステムに置いておく
- 問題
  - ファイル削除時の問題
    - データベース上でファイルパスを消しても、画像ファイル自体は消えない
    - 適切に処理しないと参照されないファイルが残り続ける
  - トランザクション分離の問題
    - トランザクションのコミット前でもファイルの変更が外から見えてしまう
  - ロールバック時の問題
    - 画像を削除した後にロールバックしても削除されたまま
  - バックアップ時の問題
    - データベースのみをバックアップするだけでは不十分
    - 画像ファイルが格納されているファイルシステムの方もバックアップが必要
  - SQL アクセス権限使用時の問題
    - `GRANT` などは、外部ファイルには当然使えない
  - ファイルの整合性の問題
    - データベースに保存されたパスに画像が存在するかをデータベースは検証できない
    - ファイル名の変更や、ファイルの移動、削除などに追従できない
- アンチパターンを使ってもよい場合
  - 画像を外部に保存する正当な理由もある
    - データベースの容量を減らせる
    - データベースのバックアップが短時間で完了し、バックアップファイルの容量も抑えられる
    - データベース外の画像ファイルはプレビューや編集が容易
  - アプリケーションによってデータベース内に格納するか、外部に格納するかを検討する必要がある
- 解決策
  - 必要に応じて BLOB 型を採用する

# 第12章 インデックスショットガン
- 闇雲にインデックスを使用するアンチパターン
- 問題
  - 不適切なインデックスはパフォーマンスを落とす
    - インデックスを全く定義しなかったり、逆に多く定義しすぎたり
  - クエリもインデックスを使うように書かなければならない
    - 複合インデックスの順序や、文字列のワイルドカード検索などに注意
- アンチパターンを使ってもよい場合
  - あるか……？
  - 十分検討して、適切にインデックスを定義する
- 解決策
  - MENTOR 原則に基づきインデックスを管理
  - Measure（測定）
    - アプリケーションで最も時間を消費しているクエリを探す
    - データベースごとに何かしら測定する仕組みがあるはず
    - クエリキャッシュを無効化することが大事
  - Explain（解析）
    - ボトルネックを見つけたら、何が原因で処理が遅くなっているかを調べる
    - `EXPLAIN` などで実行計画を見る
  - Nominate（指名）
    - 実行計画を読み、インデックスが使われていない箇所を探す
    - データベースによっては、新規インデックスの作成を含めた改善提案をしてくれるツールがあるらしい
  - Test（テスト）
    - インデックスの作成後、再度プロファイリングをする
  - Optimize（最適化）
    - キャッシュメモリを使うなど
  - Rebuild（再構築）
    - 長く使うとインデックスは次第に不均衡になっていく
    - `ANALYZE TABLE`, `VACUUM` などといったコマンドでメンテナンスできる
